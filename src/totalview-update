#!/usr/bin/python

import re
import os
import sys
import json
import time
import optparse
import ConfigParser
import urllib2
import xml.etree.ElementTree as ET
import rrdtool
import htcondor
import classad
g_startup = int(time.time())

def parse_args():
    parser = optparse.OptionParser()
    parser.add_option("-c", "--config", help="Prodview configuration file", dest="config", default=None)
    parser.add_option("-p", "--pool", help="HTCondor pool to analyze", dest="pool")
    parser.add_option("-o", "--output", help="Top-level output dir", dest="output")
    opts, args = parser.parse_args()

    if args:
        parser.print_help()
        print >> sys.stderr, "%s takes no arguments." % sys.args[0]
        sys.exit(1)

    cp = ConfigParser.ConfigParser()
    if opts.config:
        if not os.path.exists(opts.config):
            print >> sys.stderr, "Config file %s does not exist." % opts.config
            sys.exit(1)
        cp.read(opts.config)
    elif os.path.exists("/etc/prodview.conf"):
        cp.read("/etc/prodview.conf")

    if not opts.pool and cp.has_option("htcondor", "pool"):
        opts.pool = cp.get("htcondor", "pool")
    if not opts.output and cp.has_option("totalview", "basedir"):
        opts.output = cp.get("totalview", "basedir")
    opts.analysisview = cp.get("analysisview", "basedir")
    opts.prodview = cp.get("prodview", "basedir")
    opts.analysiscrab2view = cp.get("analysiscrab2view", "basedir")
    opts.scheddview = cp.get("scheddview", "basedir")
    opts.factoryview = cp.get("factoryview", "basedir")

    return opts, args

def getFromURL(url):
    try:
        req = urllib2.Request(url)
        opener = urllib2.build_opener()
        f = opener.open(req)
        return f.read()
    except urllib2.URLError as er:
        print er
        return None

def update_rrd(fname, line):
    try:
        rrdtool.update(fname, line)
    except rrdtool.error as e:
        print e
        print fname
        print line

def query_factory(coll, output):
    try:
        entries = coll.query(htcondor.AdTypes.Any, 'MyType=?="glidefactory" && GLIDEIN_CMSSite isnt undefined',['GLIDEIN_CMSSite', 'GLIDEIN_MaxMemMBs', 'GLIDEIN_Max_Walltime'])
    except IOError as er:
        print 'Failed to query factory. Error: %s' % er
        return
    for entry in entries:
        #So far it requires to -30minutes from Walltime request. TODO
        dataAppend = {'MaxMemMB': entry['GLIDEIN_MaxMemMBs'], 'MaxWallTime': int(entry['GLIDEIN_Max_Walltime']/60)}
        if entry['GLIDEIN_CMSSite'] not in output:
            output[entry['GLIDEIN_CMSSite']] = []
        InDict = False
        for item in output[entry['GLIDEIN_CMSSite']]:
            if cmp(item, dataAppend) == 0:
                InDict = True
        if not InDict:
            output[entry['GLIDEIN_CMSSite']].append(dataAppend)

def summarize_schedds(schedds_info, schedd_ads):
    for ad in schedd_ads:
        #['Name', 'CMSGWMS_Type', 'Machine', 'TotalRunningJobs', 'TotalIdleJobs', 'TotalHeldJobs', 'MaxJobsRunning']
        name = ad['Name'].replace("@", "-")
        name = name.replace(".", "-")
        schedds_info[name] = {}
        schedds_info[name]['Name'] = ad['Name']
        schedds_info[name]['FileName'] = name
        if 'CMSGWMS_Type' in ad:
            schedds_info[name]['CMSGWMS_Type'] = ad['CMSGWMS_Type']
        else:
            schedds_info[name]['CMSGWMS_Type'] = 'CRAB2'
        schedds_info[name]['Machine'] = ad['Machine']
        schedds_info[name]['TotalRunningJobs'] = ad['TotalRunningJobs']
        schedds_info[name]['TotalIdleJobs'] = ad['TotalIdleJobs']
        schedds_info[name]['TotalHeldJobs'] = ad['TotalHeldJobs']
        schedds_info[name]['MaxJobsRunning'] = ad['MaxJobsRunning']
        schedds_info[name]['PercentageUse'] = 0 if ad['TotalRunningJobs'] == 0 else int((ad['TotalRunningJobs']*100)/ad['MaxJobsRunning'])
        schedds_info[name]['Status'] = 'UNKNOWN'
        schedd_status = "UNKNOWN"
        try:
            status_expr = classad.ExprTree('ifThenElse(IsOK is undefined, "UNKNOWN", ifThenElse(IsOK,"OK", ifThenElse(IsCritical, "CRITICAL", "WARNING")))');
            schedd_status = status_expr.eval(ad)
        except:
            print 'Strange. wrong expression...', ad
            continue
        schedds_info[name]['Status'] = schedd_status

def pilotUsageInfo(coll, pilot_usage):
    pilots = []
    try:
        pilots = coll.query(htcondor.AdTypes.Any, 'GLIDEIN_CMSSite isnt undefined && SlotType isnt undefined', ['PartitionableSlot', 'GLIDEIN_CMSSite', 'TotalSlotCpus', 'Cpus', 'SlotType', 'State'])
    except IOError as er:
        print 'Got IOError %s' % er
        return
    for item in pilots:
        if 'PartitionableSlot' in item:
            #Means we have partitionable slot and some info about it
            #and we don`t care about state as in Static
            slot_info = pilot_usage.setdefault(item['GLIDEIN_CMSSite'], {}).setdefault(item['SlotType'], {'CpusUse': 0, 'CpusFree': 0})
            slot_info['CpusFree'] += int(item['Cpus'])
            slot_info['CpusUse'] += int(item['TotalSlotCpus'] - item['Cpus'])
        elif item['SlotType'] == 'Static':
            slot_info = pilot_usage.setdefault(item['GLIDEIN_CMSSite'], {}).setdefault(item['SlotType'], {'CpusUse': 0, 'CpusFree': 0})
            if item['State'] == 'Claimed':
                slot_info['CpusUse'] += 1
            elif item['State'] == 'Unclaimed':
                slot_info['CpusUse'] += 1
    #summarize
    pilot_usage['Summary'] = {}
    for item, item_dict in pilot_usage.items():
        if item == 'Summary':
            continue
        for slot, slot_dict in item_dict.items():
            out = pilot_usage.setdefault('Summary', {}).setdefault(slot, {'CpusUse': 0, 'CpusFree': 0})
            out['CpusUse'] += slot_dict['CpusUse']
            out['CpusFree'] += slot_dict['CpusFree']

def parseConfigXML(entries, output, factoryName, entryMappings):
    for entry in entries:
        entryName = entry.get('name')
        attr = entry.find('attributes')
        ettr = entry.find('descript')
        siteName = attr.get('GLIDEIN_CMSSite')
        maxHeld = ettr.get('DefaultPerFrontendMaxHeld')
        maxIdle = ettr.get('DefaultPerFrontendMaxIdle')
        if siteName and entryName and maxHeld and maxIdle:
            try:
                maxHeld = int(maxHeld)
                maxIdle = int(maxIdle)
            except:
                print 'Failed to parse value to int %s or %s' % (maxHeld, maxIdle)
                continue
            if entryName not in entryMappings:
                entryMappings[entryName] = siteName
            siteInfo = output.setdefault(siteName, {})
            entryInfo = siteInfo.setdefault(entryName, {})
            factoryInfo = entryInfo.setdefault(factoryName, {})
            factoryInfo['maxIdle'] = maxIdle
            factoryInfo['maxHeld'] = maxHeld


def appendtoOutput(output, siteName, Entry, factory, held, idle, run, err = None, warning = None):
    if siteName:
        mapped = output.setdefault(siteName, {}).setdefault(Entry, {}).setdefault(factory, {})
        mapped['nowHeld'] = int(float(held))
        mapped['nowIdle'] = int(float(idle))
        mapped['nowRunn'] = int(float(run))
        if err:
            errors = mapped.setdefault('Error', [])
            errors.append(err)
        if warning:
            warnings = mapped.setdefault('Warning', [])
            warnings.append(warning)


def parseRRDsData(entries, output, factoryName, entryMappings):
    for entry in entries:
        entryName = entry.get('name')
        frontends = entry.find('frontends')
        foundCMSpilot = False
        foundPeriod = False
        previousEntry = None
        previousSiteName = None
        if len(frontends) == 0:
            foundCMSpilot = False
            if entryName in entryMappings:
                previousSiteName = entryMappings[entryName]
                previousEntry = entryName
            err = 'This entry does not have any pool defined. Check it with factory ops.'
            appendtoOutput(output, previousSiteName, previousEntry, factoryName, 0, 0, 0, err)
            continue
        for frontend in frontends:
            frontendName = frontend.get('name')
            if entryName in entryMappings:
                previousSiteName = entryMappings[entryName]
                previousEntry = entryName
            if frontendName not in ['frontend_CMSG-v1_0_cmspilot', 'frontend_CMS_T0-Frontend_cmspilot']:
                continue
            foundCMSpilot = True
            periods = frontend.find('periods')
            for period in periods:
                pname = period.get('name')
                if int(pname) != 7200:
                    continue
                foundPeriod = True
                NowHeld = period.get('StatusHeld')
                NowIdle = period.get('StatusIdle')
                NowRunn = period.get('StatusRunning')
                if not NowHeld and not NowIdle and not NowRunn:
                    warning = 'There is no data for last 2h about running/idle/held. Maybe no one is requesting?'
                    appendtoOutput(output, previousSiteName, previousEntry, factoryName, 0, 0, 0, None, warning)
                    continue
                if entryName in entryMappings:
                    siteName = entryMappings[entryName]
                appendtoOutput(output, previousSiteName, previousEntry, factoryName, NowHeld, NowIdle, NowRunn)
        if not foundPeriod and previousEntry and previousSiteName:
            error = 'There is no data for last 2h about running/idle/held. Maybe no one is requesting?'
            appendtoOutput(output, previousSiteName, previousEntry, factoryName, 0, 0, 0, error)
        if not foundCMSpilot and previousEntry and previousSiteName:
            error = 'This factory or frontend is not requesting pilots for this entry. Or entry is in downtime. Check it with factory ops.'
            appendtoOutput(output, previousSiteName, previousEntry, factoryName, 0, 0, 0, error)


def write_schedd_info(basedir, schedds_info, fact_info):
    now = int(time.time())
    schedds_info['Summary'] = {}
    schedds_info['Summary']['UpdateTime'] = now
    drop_obj(schedds_info, basedir, 'summary.json')
    for schedd_name, schedd_dict in schedds_info.items():
        if 'Name' not in schedd_dict:
            continue
        request_dir = os.path.join(basedir, schedd_name)
        if not os.path.exists(request_dir):
            os.makedirs(request_dir)
        fname = str(os.path.join(request_dir, "request.rrd"))
        if not os.path.exists(fname):
            rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:Idle:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
            )
        update_rrd(fname, "%d:%d:%d" % (g_startup, schedd_dict["TotalRunningJobs"], schedd_dict["TotalIdleJobs"]))
    drop_obj(fact_info, basedir, 'totals.json')
    return

def load_pool_data(totals, sites, basedir, name):
    totals[name] = {}
    sites[name] = {}
    fname = os.path.join(basedir, 'totals.json')
    try:
        totalsSummary = json.load(open(fname))
        totals[name] = totalsSummary
    except:
        print 'Got Error loading file %s' % fname
    fname = os.path.join(basedir, 'site_summary.json')
    try:
        sitesSummary = json.load(open(fname))
        sites[name] = sitesSummary
    except:
        print 'Got Error loading file %s' % fname
        return False
    return True

def writeToVar(out, entry_info):
    out['Summary']['Held'] += entry_info['nowHeld']
    out['Summary']['Run'] += entry_info['nowRunn']
    out['Summary']['Idle'] += entry_info['nowIdle']
    out['Summary']['MIdle'] += entry_info['maxIdle']
    out['Summary']['MHeld'] += entry_info['maxHeld']
    out['Summary']['Errors'] += 0 if 'Error' not in entry_info else len(entry_info['Error'])
    out['Summary']['Warnings'] += 0 if 'Warning' not in entry_info else len(entry_info['Warning'])


def summarize(totals, sites, xmlout, sitesCompare, pilot_usage):
    totalR = 0
    totalI = 0
    for type, type_dict in totals.items():
        if 'Running' in type_dict.keys():
            totalR += type_dict['Running']
        if 'Idle' in type_dict.keys():
            totalI += type_dict['Idle']
    totals['Summary'] = {}
    totals['Summary']['Running'] = totalR
    totals['Summary']['Idle'] = totalI
    
    sites['Summary'] = {}
    for type, type_dict in sites.items():
        if not type == 'Summary':
            for site, site_dict in type_dict.items():
                if site and site != "Summary":
                    if site not in sites['Summary'].keys():
                        sites['Summary'][site] = {"Running": 0, "MatchingIdle": 0}
                    sites['Summary'][site]['Running'] += site_dict['Running']
                    sites['Summary'][site]['MatchingIdle'] += site_dict['MatchingIdle']
                    sites['Summary'][site][type] = site_dict
                    if site in pilot_usage:
                        sites['Summary'][site]['PilotUsage'] = pilot_usage[site]

    #Double check with what maximum was
    for site, site_dict in sites['Summary'].items():
        if site in sitesCompare and 'MaxWasRunning' in sitesCompare[site]:
            if site_dict['Running'] > sitesCompare[site]['MaxWasRunning']:
                sites['Summary'][site]['MaxWasRunning'] = site_dict['Running']
            else:
                sites['Summary'][site]['MaxWasRunning'] = sitesCompare[site]['MaxWasRunning']
        else:
            sites['Summary'][site]['MaxWasRunning'] = site_dict['Running']

    xmlout['Summary'] = {'Held': 0, 'Idle': 0, 'Run': 0, 'MHeld': 0, 'MIdle': 0, 'Errors': 0, 'Warnings': 0}
    for siteName, entries_dict in xmlout.items():
        if siteName not in ['Summary', 'Errors']:
            entries_dict["Summary"] = {'Held': 0, 'Idle': 0, 'Run': 0, 'MHeld': 0, 'MIdle': 0, 'Errors': 0, 'Warnings': 0}
            for entry, factory_dict in entries_dict.items():
                if entry in ['Summary']:
                    continue
                for factory, entry_info in factory_dict.items():
                    #fix the mess in the factory!!!
                    # Until factory will move all their xmls to somewhere where you can track history
                    # who did changes than, we need to track this down.
                    # The problem is that same entry name points to different cms sites on diff factories
                    # And one entry is on, another is off. Who forgot to update ?!
                    messedUp = False
                    for key in ['nowHeld', 'nowRunn', 'nowIdle', 'maxIdle', 'maxHeld']:
                        if key not in entry_info:
                            entry_info[key] = 0
                            messedUp = True
                    if messedUp:
                        errors = entry_info.setdefault('Error', [])
                        errors.append("Messed up! Please contact factory ops.")
                    elif entry_info['nowHeld'] > 0 and entry_info['nowHeld'] >= entry_info['maxHeld']:
                        # Everything is held and there will not be any progress until it is cleaned
                        errors = entry_info.setdefault('Error', [])
                        errors.append("Held pilots reached limit. Factory/Frontend will not request any new pilot to run until they are cleaned. Contact Factory ops to know the held reason.")
                    elif entry_info['nowIdle'] > 0 and entry_info['nowIdle'] >= entry_info['maxIdle'] and entry_info['nowRunn'] == 0:
                        warnings = entry_info.setdefault('Warning', [])
                        warnings.append("Idle pilots reached its limit and there is 0 running. Something is wrong.")
                    writeToVar(xmlout, entry_info)
                    writeToVar(entries_dict, entry_info)


def drop_obj(obj, dirname, fname):
    dirname = re.sub('[:]', '', dirname)
    fname = re.sub('[:]', '', fname)
    if not os.path.exists(dirname):
        os.makedirs(dirname)
    fname_tmp = os.path.join(dirname, fname + ".tmp")
    fname = os.path.join(dirname, fname)
    json.dump(obj, open(fname_tmp, "w"))
    os.rename(fname_tmp, fname)


def write_json(totals, sites, xmlout, output, factoryout):

    now = int(time.time())
    totals['Summary']['UpdateTime'] = now
    drop_obj(totals['Summary'], output, 'summary.json')
    drop_obj(totals, output, 'totals.json')
    sitesT = sites.setdefault('Summary', {})
    drop_obj(sitesT, output, 'site_summary.json')
    for site, site_dict in sitesT.items():
        site_dir = os.path.join(output, site)
        drop_obj(site_dict, site_dir, "summary.json")
    drop_obj(xmlout['Summary'], factoryout, 'summary.json')
    for site, site_dict in xmlout.items():
        if site in ['Errors', 'Summary']:
            continue
        site_dir = os.path.join(factoryout, site)
        drop_obj(site_dict, site_dir, 'summary.json')
    drop_obj(xmlout, factoryout, 'totals.json')


def write_rrds(totals, sites, xmlout, output, factoryout):

    running = totals['Summary']['Running']
    idle = totals['Summary']['Idle']
    fname = str(os.path.join(output, "summary.rrd"))
    if not os.path.exists(fname):
        rrdtool.create(fname,
            "--step", "180",
            "DS:Running:GAUGE:360:U:U",
            "DS:Idle:GAUGE:360:U:U",
            "RRA:AVERAGE:0.5:1:1000",
            "RRA:AVERAGE:0.5:20:2000",
        )
    update_rrd(fname, "%d:%d:%d" % (g_startup, running, idle))

    for site, site_dict in sites['Summary'].items():
        fname = str(os.path.join(output, "%s.rrd" % site))
        if not os.path.exists(fname):
            rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:MatchingIdle:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
            )
        update_rrd(fname, "%d:%d:%d" % (g_startup, site_dict["Running"], site_dict["MatchingIdle"]))
        fname = str(os.path.join(output, "%s-UTIL.rrd" % site))
        if not os.path.exists(fname):
            rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:MaxRunning:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
                )
        update_rrd(fname, "%d:%d:%d" % (g_startup, site_dict["Running"], site_dict["MaxWasRunning"]))
        if 'PilotUsage' in site_dict:
            partR = 0 if 'Partitionable' not in site_dict['PilotUsage'] else site_dict['PilotUsage']['Partitionable']['CpusUse']
            partI = 0 if 'Partitionable' not in site_dict['PilotUsage'] else site_dict['PilotUsage']['Partitionable']['CpusFree']
            statR = 0 if 'Static' not in site_dict['PilotUsage'] else site_dict['PilotUsage']['Static']['CpusUse']
            statI = 0 if 'Static' not in site_dict['PilotUsage'] else site_dict['PilotUsage']['Static']['CpusFree']
            fname = str(os.path.join(output, "%s-USAGE.rrd" % site))
            if not os.path.exists(fname):
                rrdtool.create(fname,
                   "--step", "180",
                   "DS:PartRunning:GAUGE:360:U:U",
                   "DS:PartIdle:GAUGE:360:U:U",
                   "DS:StatRunning:GAUGE:360:U:U",
                   "DS:StatIdle:GAUGE:360:U:U",
                   "RRA:AVERAGE:0.5:1:1000",
                   "RRA:AVERAGE:0.5:20:2000",
                   )
            update_rrd(fname, "%d:%d:%d:%d:%d" % (g_startup, partR, partI, statR, statI))


    #Create fake empty.rrd for sites which have no data.
    fname = str(os.path.join(output, "empty.rrd"))
    if not os.path.exists(fname):
        rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:MatchingIdle:GAUGE:360:U:U",
                "DS:MaxRunning:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
            )
        update_rrd(fname, "%d:0:0:0" % g_startup)

    fname = str(os.path.join(factoryout, 'summary.rrd'))
    summary = xmlout['Summary']
    if not os.path.exists(fname):
        rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:Idle:GAUGE:360:U:U",
                "DS:Held:GAUGE:360:U:U",
                "DS:MaxIdle:GAUGE:360:U:U",
                "DS:MaxHeld:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
                )
    update_rrd(fname, "%d:%d:%d:%d:%d:%d" % (g_startup, summary['Run'], summary['Idle'], summary['Held'], summary['MIdle'], summary['MHeld']))
    for site, site_dict in xmlout.items():
        if site in ['FactoryUrls', 'Errors', 'Summary']:
            continue
        for entry, entry_dict in site_dict.items():
            if entry == 'Summary':
                fname = str(os.path.join(factoryout, '%s.rrd' % site))
                if not os.path.exists(fname):
                    rrdtool.create(fname,
                            "--step", "180",
                            "DS:Running:GAUGE:360:U:U",
                            "DS:Idle:GAUGE:360:U:U",
                            "DS:Held:GAUGE:360:U:U",
                            "DS:MaxIdle:GAUGE:360:U:U",
                            "DS:MaxHeld:GAUGE:360:U:U",
                            "RRA:AVERAGE:0.5:1:1000",
                            "RRA:AVERAGE:0.5:20:2000",
                            )
                update_rrd(fname, "%d:%d:%d:%d:%d:%d" % (g_startup, entry_dict['Run'], entry_dict['Idle'], entry_dict['Held'], entry_dict['MIdle'], entry_dict['MHeld']))
                continue
            else:
                subsite_dir = os.path.join(factoryout, site)
                if not os.path.exists(subsite_dir):
                    os.makedirs(subsite_dir)
                for factory, factory_info in entry_dict.items():
                    newName = str(re.sub('[ ]', '', factory.lower()) + (re.sub('[ ]', '', entry)))
                    fname = os.path.join(subsite_dir, '%s.rrd' % newName)
                    if not os.path.exists(fname):
                        rrdtool.create(fname,
                                "--step", "180",
                                "DS:Running:GAUGE:360:U:U",
                                "DS:Idle:GAUGE:360:U:U",
                                "DS:Held:GAUGE:360:U:U",
                                "DS:MaxIdle:GAUGE:360:U:U",
                                "DS:MaxHeld:GAUGE:360:U:U",
                                "RRA:AVERAGE:0.5:1:1000",
                                "RRA:AVERAGE:0.5:20:2000",
                                )
                    update_rrd(fname, "%d:%d:%d:%d:%d:%d" % (g_startup, factory_info['nowRunn'], factory_info['nowIdle'], factory_info['nowHeld'], factory_info['maxIdle'], factory_info['maxHeld']))

def main():
    opts, args = parse_args()

    if opts.pool:
        coll = htcondor.Collector(opts.pool)
    else:
        coll = htcondor.Collector()

    # Has to be moved below
    fact_out = {} # Used from condor
    xml_out = {} # Used from parsing xmls
    entryMappings = {} # Used for entries mapping from factory xmls
    #Move this list to configuration
    for factory in ['gfactory-1.t2.ucsd.edu', 'cmsgwms-factory.fnal.gov', 'glidein.grid.iu.edu', 'vocms0305.cern.ch']:
        print 'Query %s factory' % factory
        collF = htcondor.Collector(factory)
        query_factory(collF, fact_out)
    #Get schedulers information
    schedds_info = {}
    schedd_ads = []
    try:
        schedd_ads = coll.query(htcondor.AdTypes.Schedd, 'True',['Name', 'CMSGWMS_Type', 'Machine', 'TotalRunningJobs', 'TotalIdleJobs', 'TotalHeldJobs', 'MaxJobsRunning', 'IsOK', 'isWarning', 'isCritical'])
    except IOError as er:
        print 'Got IOError %s' % er
    if schedd_ads:
        summarize_schedds(schedds_info, schedd_ads)
    write_schedd_info(opts.scheddview, schedds_info, fact_out)

    pilot_usage = {} 
    totals = {}
    sites = {}

    pilotUsageInfo(coll, pilot_usage)
    load_pool_data(totals, sites, opts.analysisview, "analysisview")
    load_pool_data(totals, sites, opts.prodview, "prodview")
    load_pool_data(totals, sites, opts.analysiscrab2view, "analysiscrab2view")

    max_resources = {}
    max_totals = {}
    i = 0
    while i < 5:
        success = load_pool_data(max_totals, max_resources, opts.output, "totalview")
        if success:
            break
        print 'Failed to load site data for resource utilization'
        time.sleep(1)
        i += 1
    #Move this list to configuration also
    urls = [{"FNAL Factory" :"http://cmsgwms-factory.fnal.gov:8319/factory/monitor/"},
            {"GOC Factory" : "http://glidein.grid.iu.edu/factory/monitor/"},
            {"UCSD Factory" : "http://gfactory-1.t2.ucsd.edu/factory/monitor/"},
            {"CERN Factory" : "http://vocms0305.cern.ch/monitor/"}]
    appends = ['descript.xml', 'rrd_Status_Attributes.xml']
    errors = xml_out.setdefault("Errors", [])
    for appendId in [0, 1]:
        for url_ in urls:
            factoryName, url = url_.items()[0]
            urlD = url + appends[appendId]
            factory_xml = getFromURL(urlD)
            if not factory_xml:
                errors.append("Failed to parse %s info from %s url" % (factoryName, urlD))
                continue
            root = ET.fromstring(factory_xml)
            entries = root.find('entries')
            if appendId == 0:
                parseConfigXML(entries, xml_out, factoryName, entryMappings)
            else:
                parseRRDsData(entries, xml_out, factoryName, entryMappings)
    summarize(totals, sites, xml_out, max_resources['totalview'], pilot_usage)
    xml_out["Summary"]["FactoryUrls"] = {}
    for url_ in urls:
        factoryName, url = url_.items()[0]
        xml_out["Summary"]["FactoryUrls"][factoryName] = url
    if opts.output:
        write_json(totals, sites, xml_out, opts.output, opts.factoryview)
        write_rrds(totals, sites, xml_out, opts.output, opts.factoryview)

if __name__ == "__main__":
    main()

